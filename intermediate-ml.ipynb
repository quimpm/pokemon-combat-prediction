{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intermediate Machine Learning\n",
    "\n",
    "In this notebook we will present some intermediate Machine Learning (ML) approaches and concepts.\n",
    "\n",
    "In particular, we will learn:\n",
    "- How to use pipelines and column transformers to simplify the data preprocessing steps\n",
    "- How to evaluate our models\n",
    "- How to fine-tune our models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines and ColumnTranformers\n",
    "\n",
    "Previously we have seen how to perform some basic preprocessing steps to a dataset. We have realized that it can be very tedious to apply to the test set the same preprocessing that we applied to the training set. We will learn how to simplify this process by grouping transformers through Pipelines and ColumnTransformers.\n",
    "\n",
    "Let's start by loading the *Titanic* dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "titanic = pandas.read_csv(\"https://hbiostat.org/data/repo/titanic.txt\", index_col=0)\n",
    "\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "titanic_X = titanic.drop(\"survived\", axis=1)\n",
    "titanic_y = titanic[\"survived\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    titanic_X, titanic_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's apply the same preprocessing that we have seen previously, but now using Pipelines and ColumnTransformers:\n",
    "\n",
    "- Select a subset of the features\n",
    "- Impute missing values by using different strategies for categorical and numerical features\n",
    "- Encode categorical features\n",
    "\n",
    "At the end we will also use a DecisionTreeClassifier to make our predictions.\n",
    "\n",
    "[Pipeline documentation](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline)\n",
    "\n",
    "[ColumnTransformer documentation](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html?highlight=columntransformer#sklearn.compose.ColumnTransformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "num = [\"age\"]\n",
    "cat = [\"pclass\", \"sex\"]\n",
    "\n",
    "predictor = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"preprocessing\", ColumnTransformer(\n",
    "                [\n",
    "                    (\n",
    "                        \"cat\",\n",
    "                        make_pipeline(\n",
    "                            SimpleImputer(strategy=\"most_frequent\"),\n",
    "                            OneHotEncoder(sparse=False, drop=\"first\"),\n",
    "                        ),\n",
    "                        cat\n",
    "                    ),\n",
    "                    (\"num\", SimpleImputer(strategy=\"mean\"), num),\n",
    "                ],\n",
    "                remainder=\"drop\",\n",
    "            )\n",
    "        ),\n",
    "        (\"predictor\", DecisionTreeClassifier(criterion=\"entropy\", max_depth=3, min_samples_leaf=5)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we can fit our `predictor` Pipeline using the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we did not preprocess our `X_train`! This is already done by our pipeline when we call the `fit` method.\n",
    "\n",
    "Now, let's check which is our score in the training set and predict our test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train score:\", predictor.score(X_train, y_train))\n",
    "y_test_pred = predictor.predict(X_test)\n",
    "y_test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, all the preprocessing defined in our pipeline is applied to the data automatically.\n",
    "\n",
    "In general, when using pipelines, we do not have to worry about the `transform` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics\n",
    "\n",
    "We have seen how we can compute the accuracy score of a prediction. In particular, its mathematical formula would be:\n",
    "\n",
    "$$accuracy(y, ŷ) = \\frac{1}{n_{samples}} \\sum_{i=0}^{n_{samples} - 1} 1(ŷ_i = y_i)$$\n",
    "\n",
    "Now, imagine that we have the following $y$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "y = numpy.array(([1] * 95) + ([0] * 5))\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, imagine that we came out with a model that obtains a **95% of accuracy!**\n",
    "\n",
    "Nice! What a great result! Sure..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = numpy.ones(100)\n",
    "accuracy_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It results that our *great* predictor was always predicting the same class, and as result of our unbalanced target we end up obtaining a 95% of accuracy.\n",
    "\n",
    "This means that we cannot always base our model evaluation just on the basic accuracy score. In the next section we will discuss other alterative metrics that we can use to better evaluate our models.\n",
    "\n",
    "But first we must understant what the *confusion matrix* is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Confusion Matrix\n",
    "\n",
    "The Confusion Matrix is a visualization of the performance of a prediction in the following form:\n",
    "\n",
    "![confusion matrix](https://2.bp.blogspot.com/-EvSXDotTOwc/XMfeOGZ-CVI/AAAAAAAAEiE/oePFfvhfOQM11dgRn9FkPxlegCXbgOF4QCLcBGAs/s1600/confusionMatrxiUpdated.jpg)\n",
    "\n",
    "**NOTE:** We will study the Confusion Matrix and its derived metrics using *binary* classification, but all these concepts can be easily extendened to *multilabel* classification.\n",
    "\n",
    "Scikit-learn also provides a method to compute Confusion Matrices ([docu](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf_matrix = confusion_matrix(y, y_pred)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A better representation (requires matplotlib):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "disp = ConfusionMatrixDisplay(conf_matrix)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanced accuracy score\n",
    "\n",
    "This metric is similar as the conventional accuracy score, but takes into account the class imbalance:\n",
    "\n",
    "$$balanced-accuracy = \\frac{1}{2}(\\frac{TP}{TP + FN} + \\frac{TN}{TN + FP})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "balanced_accuracy_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision score\n",
    "\n",
    "This metric measures the ability of the classifier not to label as positive a sample that is negative:\n",
    "\n",
    "$$precision = \\frac{TP}{TP + FP}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall score\n",
    "\n",
    "This metric measure he ability of the classifier to find all the positive samples:\n",
    "\n",
    "$$recall = \\frac{TP}{TP + FN}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "recall_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can try to apply different metrics to our predictions in the *Titanic* dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation approaches\n",
    "\n",
    "Until now, we have only seen one *valid* approach to evaluate our models: the training-test split.\n",
    "\n",
    "In this section we will review an alternative approach that is called *cross-validation*.\n",
    "\n",
    "### Cross-validation\n",
    "\n",
    "Sometimes we may want to use all the available data for training purposes. In this case splitting the dataset as we were doing until now will not be an option.\n",
    "\n",
    "However, recall that we cannot evaluate our model using the same data that we used for training! We can take a mixed approach called **cross-validation**.\n",
    "\n",
    "![Cross-validation](https://scikit-learn.org/stable/_images/grid_search_cross_validation.png)\n",
    "\n",
    "([source](https://scikit-learn.org/stable/modules/cross_validation.html))\n",
    "\n",
    "This evaluation methodology is very common to evaluate the performance of different models over a dataset before applying them to the final testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score(predictor, X_train, y_train, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning\n",
    "\n",
    "As you know, the models that we are using can expose many configurable parameters that can be fine-tuned.\n",
    "\n",
    "This is an ardous task if we have to perform it by hand. Scikit-learn tries to simplify this process by providing the `GridSearchCV` and `RandomizedSearchCV` classes.\n",
    "\n",
    "### GridSearchCV\n",
    "\n",
    "This class will **exhaustively search** over all the specified parameter values for an estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {\n",
    "    \"preprocessing__num__strategy\": (\"mean\", \"median\"),\n",
    "    \"predictor__criterion\": (\"gini\", \"entropy\"),\n",
    "    \"predictor__max_depth\": (3, 5, 10),\n",
    "    \"predictor__min_samples_leaf\": (5, 10, 20),\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(predictor, parameters, cv=5)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"* Original test score:\", predictor.score(X_test, y_test))\n",
    "print(\"* GridSearchCV test score:\", clf.best_estimator_.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomSearchCV\n",
    "\n",
    "If we have a large amount of parameters and values, using `GridSearchCV` is unfeasible. We should take an imcomplete appoach instead, such as `RandomizedSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "parameters = {\n",
    "    \"preprocessing__num__strategy\": (\"mean\", \"median\"),\n",
    "    \"predictor__criterion\": (\"gini\", \"entropy\"),\n",
    "    \"predictor__max_depth\": list(range(3, 20)),\n",
    "    \"predictor__min_samples_leaf\": list(range(1, 100)),\n",
    "}\n",
    "\n",
    "clf = RandomizedSearchCV(predictor, parameters, cv=5, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"* Original test score:\", predictor.score(X_test, y_test))\n",
    "print(\"* RandomizedSearchCV test score:\", clf.best_estimator_.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fd9d57ba6a769d4bcad9aeb21297dde241a507ba8fbb3f8e30b8ae5b0b06d636"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

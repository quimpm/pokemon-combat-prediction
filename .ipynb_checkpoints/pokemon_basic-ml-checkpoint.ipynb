{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5100e620-aba9-4f0f-93bc-cab59a4a4026",
   "metadata": {},
   "source": [
    "# Assignment 2 - Basic Machine Learning to predict Pokémon battles results\n",
    "\n",
    "([From Wikipedia](https://en.wikipedia.org/wiki/Pok%C3%A9mon)) *Pokémon is a Japanese media franchise managed by The Pokémon Company, a company founded by Nintendo, Game Freak, and Creatures. The franchise was created by Satoshi Tajiri in 1996,[4] and is centered on fictional creatures called \"Pokémon\". In Pokémon, humans, known as Pokémon Trainers, catch and train Pokémon to battle other Pokémon for sport.*\n",
    "\n",
    "In this assignment we present you a dataset with the results of several Pokémon battles.\n",
    "\n",
    "Your objective will be to produce a ML model that can predict the outcomes of any Pokémon battle.\n",
    "\n",
    "At first, in this notebook, you will apply some of the basic ML approaches that we have seen in class. At this point you can also work with the *small* versions of the dataset if you want.\n",
    "\n",
    "Later, on the `pokemon-competition.ipynb` notebook, you will train a model using all the data that will be used to predict *real* Pokémon battles.\n",
    "\n",
    "**Dataset Description**\n",
    "\n",
    "Within the `datasets.zip` file that you can download from the virtual campus, you will find the following datasets:\n",
    "\n",
    "- data.train -> Full data available to train the models\n",
    "- data_inverse.train -> Same data as data.train but each combat is seen from the other player's perspective (i.e. pokemon1 becomes pokemon2 and viceversa)\n",
    "- small.train -> Subsample of data.train to allow fast prototyping\n",
    "- small_inverse.train -> Subsample of data_inverse.train to allow fast prototyping\n",
    "- data.hidden -> Dataset with no label available\n",
    "- data_inverse.hidden -> Same as data.hidden but the pokemons are inverted\n",
    "\n",
    "The datasets *.hidden are the ones used to get the tournament score,\n",
    "so the true label is unknown. All the other datasets are available to\n",
    "you to use however you want.\n",
    "\n",
    "*Gotta Train 'Em All!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a4817b09-c29c-48cb-9573-2b57f1eb828f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas\n",
    "\n",
    "__wd__ = Path(\"__file__\").resolve().parent\n",
    "datasets_path = __wd__ / \"datasets\"\n",
    "\n",
    "data = pandas.read_csv(datasets_path / \"data.train\", index_col=0)\n",
    "inverse_data = pandas.read_csv(datasets_path / \"data_inverse.train\", index_col=0)\n",
    "\n",
    "def get_Xy(dataset):\n",
    "    return dataset.drop(\"Wins\", axis=1), dataset[\"Wins\"]\n",
    "\n",
    "X, y = get_Xy(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c41f9e74-4521-413c-9f77-ed70e05b8cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your imports here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2028a1d7-7aac-4606-b742-640fc4aefe25",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Part 1 - Analyze the dataset (2 points)\n",
    "The first step of any ML process is to know the data we are dealing with. In this part, you have to analyze the dataset and answer the questions below.\n",
    "\n",
    "1. Which features are categorical? Which are continuous?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "449dea12-b977-43e4-b454-6eeb6b62d034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d6fdf6-20ac-4c0c-b0fc-e39941f774cc",
   "metadata": {},
   "source": [
    "2. Observe the distribution of the \"Type 1\" variable. Use a plot to show this distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973db97c-436b-480c-924b-76f19f78f619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f024e8b3-590e-4908-8e1e-a77673ec6db2",
   "metadata": {},
   "source": [
    "3. Determine which of the features have missing values. How many missing values there are for each one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f0dc1e-d1a5-4d06-aaa8-eec8ba0d306f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f983236-2bf6-495f-adc2-266c0dba82e6",
   "metadata": {},
   "source": [
    "4. Analize the distribution of the target column. Is it balanced?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a253ecaf-ee73-42ce-a8eb-db7d23862356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bd9135-71cf-4624-8a35-208a23faaaeb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Part 2 - Preprocess the data (3 points)\n",
    "Once we know how the dataset is, we can proceed with the cleaning of the data. This includes:\n",
    "\n",
    "- Select the features that you want to use (p.e. removing too specific features). Explain why each feature is used or discarded.\n",
    "- Impute the missing values. Explain why you use this imputer and not another one. If you use different imputers for different features, explain the reason why you do this.\n",
    "- Encode the values of the features to work with the model you choose. This can be either encoding the categorical values, or discretizing continuous values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bf69c3b-a774-4386-bfed-42e127964245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616b803e-0f87-41dc-a1a9-a7256fb824ba",
   "metadata": {},
   "source": [
    "## Part 3 - Training your model (3 points)\n",
    "In this part you have to train a **classifier** model to predict if a Pokemon will win or not a battle against another Pokemon. For this, you should explore at least 3 different classifiers.\n",
    "\n",
    "You have to train and evaluate those classifiers using cross-validation in order to select the best one. Then, you should also study the results of the model (overfit, underfit, possible bias...).\n",
    "\n",
    "1. Train (at least) 3 different classifiers\n",
    "2. Evaluate the 3 classifiers using cross-validation. Select the best model according to this metric.\n",
    "3. For the selected model: \n",
    "   1. Get the accuracy for data not seen during the training process\n",
    "   2. Plot the confusion matrix\n",
    "   3. Analize the results of accuracy and the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5457ef8-37b1-4a60-bc0a-6eef63ddb6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc186c17-b9e0-4ad6-82a9-6b638ab41d0d",
   "metadata": {},
   "source": [
    "## Part 4 (Optional) - Create an ensemble and configure the model\n",
    "\n",
    "You have trained different classifiers but selected only one of them as \"the best\" one. Maybe instead of having the models competing between them, having them to colaborate would yield better results. \n",
    "\n",
    "We propose you to create an ensemble of the different classifiers explored in *Part 3*. You should compare the ensemble with the individual models using cross-validation, and then get the final accuracy and the confusion matrix for the ensemble.\n",
    "As a bonus, try to tune the parameters of this ensemble using either `GridSearchCV` or `RandomizedSearchCV`.\n",
    "\n",
    "1. Train an ensemble with the classifiers in *Part 3*.\n",
    "2. Compare the performance of this ensemble using cross-validation, the final accuracy, and the confusion matrix. Analyze the results.\n",
    "3. Fine-tune the hyper-parameters of the ensemble using `GridSearchCV` or `RandomizedSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f8a7e8-0d31-44a0-bbfa-ed74337edf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b2b144-ee23-4c6a-b8c8-4abf6e85dedb",
   "metadata": {},
   "source": [
    "## Part 5 - Wrap-up (2 points)\n",
    "The final part of this assignment is to wrap-up your classifier into a pipeline. This pipeline will execute the entire process:\n",
    "\n",
    "- Preprocess the data\n",
    "    - Select features\n",
    "    - Impute data\n",
    "    - Encode values\n",
    "- The classifier selected in *Part 3* (or the ensemble if it is better)\n",
    "\n",
    "This pipeline will be used in the other provided notebook to generate the predictions for the combats you have to submit.\n",
    "\n",
    "To ensure everything works as expected, we recommend you to load the dataset again before using it with the pipeline. You should also compare the accuracy and the confusion matrix from the pipeline with the model trained before. **Remember to set the random state to all the required transformers and estimators to have a constant output**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f464b6bb-4f99-4671-ba66-5f8d93ee1a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
